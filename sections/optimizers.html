<h1>
    Optimizers
</h1>

<p>
    An AI model is really a parametrized composition of functions. In this framework, these compositions are implemented using the Module class. The Module contains "parameters", and the output of the Module depends not only on the input, but also on what these parameters are. For every input, the output of the Module is passed into a loss function, which produces a scalar loss representing the "quality" of the Module output. By calling backwards upon that scalar, we can obtain the gradient for every parameter in the Module, and by modifying the parameters in the negative direction of the gradient, we can decrease the loss for that output, thus improving the Module. This is the theory behind gradient descent. 
</p>

<p>
    There is no single way to update model parameters given a gradient. The simplest way is to subtract a small fraction of the gradient from the parameters. This is the strategy taken by stochastic gradient descent (SGD). 
</p>

<p>
    In the most general sense, an optimizer is an object that, given a list of parameters and their gradients, applies a modification to those parameters. Each optimizer must implement its own .update_parameters() methods. 
</p>

<p>
    In order to understand how an optimizer fits into a training loop, please have a look at the demo notebook to see how modules, optimizers, and gradients all work together. The demo is also available <a href="https://github.com/michaelkosmider/dlminibox/blob/main/demo.ipynb" target="_blank">here</a>.
</p>

<iframe id="demoFrame"
        src="demo.html"
        width="100%"
        style="border: none;"
        onload="resizeIframe(this)"
        scrolling="no">
</iframe>